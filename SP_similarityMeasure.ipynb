{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#from utils.polyhierarchy_comparison_measures import SP_weighted_embeddings_wordnet,SP_max_embeddings_wordnet\n",
    "import itertools\n",
    "import logging\n",
    "import operator\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import networkx as nx\n",
    "import glob\n",
    "from scipy import stats\n",
    "from numpy.random import randn\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "wn_lemma = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_diag(self, values): \n",
    "    n = min(len(self.index), len(self.columns))\n",
    "    self.values[tuple([np.arange(n)] * 2)] = values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt; plt.ion()\n",
    "import networkx as nx\n",
    "\n",
    "def find_lowest_common_ancestor(graph, a, b):\n",
    "    \"\"\"\n",
    "    Find the lowest common ancestor in the directed, acyclic graph of node a and b.\n",
    "    The LCA is defined as on\n",
    "\n",
    "    @reference:\n",
    "    https://en.wikipedia.org/wiki/Lowest_common_ancestor\n",
    "\n",
    "    Notes:\n",
    "    ------\n",
    "    This definition is the opposite of the term as it is used e.g. in biology!\n",
    "\n",
    "    Arguments:\n",
    "    ----------\n",
    "        graph: networkx.DiGraph instance\n",
    "            directed, acyclic, graph\n",
    "\n",
    "        a, b:\n",
    "            node IDs\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        lca: [node 1, ..., node n]\n",
    "            list of lowest common ancestor nodes (can be more than one)\n",
    "    \"\"\"\n",
    "\n",
    "    assert nx.is_directed_acyclic_graph(graph), \"Graph has to be acyclic and directed.\"\n",
    "\n",
    "    # get ancestors of both (intersection)\n",
    "    common_ancestors = list(nx.ancestors(graph, a) & nx.ancestors(graph, b))\n",
    "    \n",
    "    # get sum of path lengths\n",
    "    sum_of_path_lengths = np.zeros((len(common_ancestors)))\n",
    "    for ii, c in enumerate(common_ancestors):\n",
    "        sum_of_path_lengths[ii] = nx.shortest_path_length(graph, c, a) \\\n",
    "                                  + nx.shortest_path_length(graph,  c,b)\n",
    "\n",
    "    # print common_ancestors\n",
    "    # print sum_of_path_lengths\n",
    "    \n",
    "    # return minima\n",
    "    minima, = np.where(sum_of_path_lengths == np.min(sum_of_path_lengths))\n",
    "    #print(minima)\n",
    "    return min(sum_of_path_lengths)\n",
    "    #return [common_ancestors[ii] for ii in minima]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_file = './Graph/Noungraph_wordsimilarity.csv'\n",
    "df = pd.read_csv(graph_file)\n",
    "G = nx.from_pandas_edgelist(df,\n",
    "                            source='parent',\n",
    "                            target='child',\n",
    "                            create_using=nx.DiGraph())\n",
    "# find level of node(shortest path from root to current node)\n",
    "optional_attrs = nx.shortest_path_length(G ,'root')\n",
    "nx.set_node_attributes(G ,  optional_attrs, 'node_level' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for the input words and 3 related synsets in the wordnet\n",
    "wn_lemma = WordNetLemmatizer()\n",
    "def word_synset3_dict(concept_names, word_type='noun'):\n",
    "    leaf_nodes = dict()\n",
    "    for c in concept_names:\n",
    "        \n",
    "        ls= []\n",
    "        \n",
    "        word1 = wn_lemma.lemmatize(c)\n",
    "        \n",
    "        if word_type=='verb':\n",
    "            count = 0\n",
    "            for result in wn.synsets(word1, pos = wn.VERB): # retrieve all concepts related to this word\n",
    "                if count<20:\n",
    "                    ls.append(result.name())\n",
    "                    count+=1\n",
    "                if ls:\n",
    "                    leaf_nodes[word1] = ls\n",
    "        if word_type=='noun':\n",
    "            count = 0\n",
    "            for result in wn.synsets(word1, pos = wn.NOUN): # retrieve all concepts related to this word\n",
    "\n",
    "                # only add corresponding noun synsets '.n.' in result.name() and \n",
    "                if count<20:\n",
    "                    ls.append(result.name())\n",
    "                    count+=1\n",
    "                if ls:\n",
    "                    leaf_nodes[word1] = ls\n",
    "\n",
    "        \n",
    "    return leaf_nodes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for the input words and 3 related synsets in the wordnet\n",
    "\n",
    "def word_synsetall_dict(concept_names, pos):\n",
    "    leaf_nodes = dict()\n",
    "    for c in concept_names:\n",
    "        ls= []\n",
    "        count = 0\n",
    "        word1 = wn_lemma.lemmatize(c)\n",
    "        for result in wn.synsets(word1): # retrieve all concepts related to this word\n",
    "                ls.append(result.name())\n",
    "        if ls:\n",
    "            leaf_nodes[word1] = ls\n",
    "    return leaf_nodes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE embeddings based on common ancestors between two nodes.\n",
    "def SP_embeddings_wordnet(filename, target_filename,rootnode, word_pairs, lambda_factor=0.7, concept_dict=None):\n",
    "    df = pd.read_csv(filename)\n",
    "    # Create the Directed Graph \n",
    "    try:\n",
    "        G = nx.from_pandas_edgelist(df,\n",
    "                            source='parent',\n",
    "                            target='child',\n",
    "                            create_using=nx.DiGraph())\n",
    "        # find level of node(shortest path from root to current node)\n",
    "        optional_attrs = nx.shortest_path_length(G ,rootnode)\n",
    "        nx.set_node_attributes(G ,  optional_attrs, 'node_level' )\n",
    "        \n",
    "        #word_pairs = list(itertools.product(list(concept_dict.keys()), repeat=2)) # create pair of all nodes \n",
    "       \n",
    "        ancestors_distance = {}\n",
    "        for word in word_pairs:        \n",
    "            if word[0]== word[1]:\n",
    "                ancestors_distance[word]=1\n",
    "            else:\n",
    "                common_ancestor = {} \n",
    "                # fetch synsets from the graph for both words\n",
    "                if concept_dict:\n",
    "                    concepts_word1 = concept_dict[word[0]]\n",
    "                    concepts_word2 = concept_dict[word[1]]\n",
    "                else:\n",
    "                    print (word)\n",
    "                    break\n",
    "                pairs = list(itertools.product(concepts_word1, concepts_word2)) # create pair of all nodes \n",
    "                \n",
    "                ls_similarity = []\n",
    "                \n",
    "                distance_list=[]\n",
    "                distance_dict= {}\n",
    "                for i in pairs:\n",
    "                    minima = find_lowest_common_ancestor (G, i[0], i[1])\n",
    "                    sim_m = lambda_factor**(( minima)/2) # divide may lead to float lamads , 2, 2,5                 \n",
    "                    #distance_dict[i] = np.max(ls_distance)\n",
    "                    distance_list.append (sim_m) # choose the distance for lowest common ancestor for given concept pair\n",
    "\n",
    "                \n",
    "                ancestors_distance[word] =   np.max(distance_list)\n",
    "\n",
    "\n",
    "                \n",
    "        chunked_data = [[k[0],k[1], v] for k, v in ancestors_distance.items()]\n",
    "        df_nodes = pd.DataFrame(chunked_data)\n",
    "        df_nodes = df_nodes.rename(columns= {0:'node1', 1:'node2', 2:'weight'})\n",
    "        \n",
    "        \n",
    "        # create adjancey matrix\n",
    "        df_nodes.to_csv(target_filename)\n",
    "        \n",
    "        \n",
    "    except BaseException:\n",
    "        logging.exception(\"An exception was thrown!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = glob.glob(\"datasets/*.csv\")\n",
    "data_files = ['datasets/NOUN_rw.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NOUN_rw.csv\n",
      "NOUN_rw.csv\n"
     ]
    }
   ],
   "source": [
    "graph_file = './Graph/graph_wordsimilarity.csv'\n",
    "#graph_file = './Graph/Noungraph_wordsimilarity.csv'\n",
    "#data_files = glob.glob(\"datasets/*.csv\")\n",
    "#data_files =[\"datasets/NOUN_mc-30.csv\"]\n",
    "lambda_factor= 0.55#0.755 #0.9\n",
    "strategy = 'SP'\n",
    "column_names = ['word1', 'word2', 'sim']\n",
    "root_node = 'root'\n",
    "count =0\n",
    "for file in data_files:\n",
    "    print (file)\n",
    "    if count==10:\n",
    "        break\n",
    "    else:\n",
    "        count +=1\n",
    "        targetfile = file.split('/')[1]\n",
    "        word_list = []\n",
    "        df = pd.read_csv(file) #,  names = column_names)#sep=';',\n",
    "        \n",
    "        word_list.append(df['word1'])\n",
    "        word_list.append(df['word2'])  \n",
    "        word_list = list(set([item for sublist in word_list for item in sublist]))\n",
    "        \n",
    "        \n",
    "        # create dictionary of word synsets from given word list\n",
    "        if file.split('/')[1].split('_')[0].lower() =='noun':\n",
    "            print (file.split('/')[1])\n",
    "            leaf_nodes = word_synset3_dict(word_list, 'noun')\n",
    "\n",
    "            wd1 = [wn_lemma.lemmatize(w) for w in df['word1']]\n",
    "            wd2 = [wn_lemma.lemmatize(w) for w in df['word2']]\n",
    "            word_pairs = list(zip(wd1, wd2))\n",
    "            \n",
    "            ls = leaf_nodes.keys() \n",
    "            # call all functions for each dataset\n",
    "            \n",
    "            if leaf_nodes :\n",
    "                \n",
    "                SP_embeddings_wordnet(graph_file,  './sim_scores/SP/'+targetfile, root_node ,word_pairs,lambda_factor, leaf_nodes)\n",
    "            else:\n",
    "                print ('No data found')\n",
    "\n",
    "\n",
    "        elif file.split('/')[1].split('_')[0].lower() =='verb':\n",
    "            print (file.split('/')[1])\n",
    "            leaf_nodes = word_synset3_dict(word_list, 'verb')\n",
    "            #\n",
    "            wd1 = [wn_lemma.lemmatize(w) for w in df['word1']]\n",
    "            wd2 = [wn_lemma.lemmatize(w) for w in df['word2']]\n",
    "            word_pairs =list(zip(wd1, wd2))\n",
    "        \n",
    "            ls = leaf_nodes.keys() \n",
    "           \n",
    "            # call all functions for each dataset\n",
    "            if leaf_nodes :\n",
    "                \n",
    "                SP_embeddings_wordnet(graph_file,  './sim_scores/SP/'+targetfile, root_node ,word_pairs,lambda_factor, leaf_nodes)\n",
    "            else:\n",
    "                pass\n",
    "                #print ('No data found')\n",
    "        else:\n",
    "            #leaf_nodes = None\n",
    "            pass\n",
    "        \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = []\n",
    "for i in wd2:\n",
    "    if i in leaf_nodes:\n",
    "        pass\n",
    "    else:\n",
    "        ls.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls1 = []\n",
    "for i in wd1:\n",
    "    if i in leaf_nodes:\n",
    "        pass\n",
    "    else:\n",
    "        ls1.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('datasets/NOUN_rw.csv')\n",
    "df = df.loc[~df['word2'].isin(ls)]\n",
    "df = df.loc[~df['word1'].isin(ls1)]\n",
    "\n",
    "\n",
    "#df.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word1</th>\n",
       "      <th>word2</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [word1, word2, similarity]\n",
       "Index: []"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['word2'].isin(ls)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sim_scores/SP/NOUN_rg-65.csv\n",
      "\n",
      "65\n",
      "65\n",
      "0.81\n",
      "0.76\n",
      "./sim_scores/SP/NOUN_mturk-287.csv\n",
      "\n",
      "243\n",
      "243\n",
      "0.33\n",
      "0.26\n",
      "./sim_scores/SP/NOUN_wordsim353-rel.csv\n",
      "\n",
      "248\n",
      "248\n",
      "0.07\n",
      "0.0\n",
      "./sim_scores/SP/NOUN_mc-30.csv\n",
      "\n",
      "30\n",
      "30\n",
      "0.72\n",
      "0.71\n",
      "./sim_scores/SP/NOUN_wordsim353-sim.csv\n",
      "\n",
      "201\n",
      "201\n",
      "0.61\n",
      "0.59\n",
      "./sim_scores/SP/NOUN_rw.csv\n",
      "\n",
      "865\n",
      "910\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-e8f0d2241e56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;31m# calculate Pearson's correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mcorrp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0mpearson_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   3833\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3835\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x and y must have the same length.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have the same length."
     ]
    }
   ],
   "source": [
    "pearson_ls = []\n",
    "spearman_ls = [] \n",
    "result_dict = {}\n",
    "goldDatapath= './datasets/'\n",
    "sim_data = glob.glob(\"./sim_scores/SP/*.csv\")\n",
    "column_names = ['word1', 'word2', 'sim']\n",
    "algos = [  'lch']\n",
    "columns =['SimLex222','Agirre201', 'Gerz', 'Millers', 'Rel122', 'wordsim353', 'yang' ]\n",
    "df_score =pd.DataFrame(columns=columns)\n",
    "index_ls = []\n",
    "for file in sim_data:\n",
    "    print (file)\n",
    "    algoname = file.split('/')[2].split('sss')[0]\n",
    "    \n",
    "    filename = file.split('/')[-1]\n",
    "    print ()\n",
    "    for algoname in algos:\n",
    "        # read similarity file\n",
    "        df_r = pd.read_csv(file)\n",
    "        # read human similarity score\n",
    "        df = pd.read_csv(goldDatapath+filename)\n",
    "        score_human = df['similarity'].values\n",
    "        norm1 = [(float(i)-min(score_human))/(max(score_human )-min(score_human )) for i in score_human ] # normalize score in 0-1\n",
    "        norm1 = np.round(norm1,2)\n",
    "\n",
    "        algo_score = np.round( df_r['weight'].values,2)\n",
    "        # normalize score\n",
    "        #if (df_r['weight'] > 1).any():\n",
    "        #algo_score= [(float(i)-min(algo_score))/(max(algo_score )-min(algo_score )) for i in algo_score ] # normalize score in 0-1\n",
    "        print (len(algo_score))\n",
    "        print (len(norm1))\n",
    "        # calculate Pearson's correlation\n",
    "        corrp, _ = pearsonr(norm1, algo_score)\n",
    "        pearson_ls.append(corrp) \n",
    "        print (np.round(corrp,2))\n",
    "        corrs, _ = spearmanr(norm1, algo_score)\n",
    "        #print('Spearmans correlation: %.3f' % corr)\n",
    "        spearman_ls.append(corrs) \n",
    "        print (np.round(corrs,2))\n",
    "#df_score.loc[len(df_score.index)+1] =pearson_ls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "865\n",
      "910\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have the same length.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-e39f9636b46e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;31m# calculate Pearson's correlation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcorrp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpearsonr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgo_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mpearson_ls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mpearsonr\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   3833\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3835\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'x and y must have the same length.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3836\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have the same length."
     ]
    }
   ],
   "source": [
    "df_r = pd.read_csv('./sim_scores/SP/NOUN_rw.csv')\n",
    "# read human similarity score\n",
    "df = pd.read_csv('datasets/NOUN_rw.csv')\n",
    "\n",
    "algo_score = np.round( df_r['weight'].values,2)\n",
    "#df = df.loc[df.word2.isin(df_r.node2.values)]\n",
    "\n",
    "#ls = list(set(df['word1'].values) - set(df_r['node1'].values))\n",
    "#print (len(ls))\n",
    "#df = df.loc[~df.word1.isin(ls)]\n",
    "\n",
    "\n",
    "score_human = df['similarity'].values\n",
    "norm1 = [(float(i)-min(score_human))/(max(score_human )-min(score_human )) for i in score_human ] # normalize score in 0-1\n",
    "norm1 = np.round(norm1,2)\n",
    "\n",
    "print (len(algo_score))\n",
    "print (len(norm1))\n",
    "\n",
    "\n",
    "# calculate Pearson's correlation\n",
    "corrp, _ = pearsonr(norm1, algo_score)\n",
    "pearson_ls.append(corrp) \n",
    "print (np.round(corrp,2))\n",
    "corrs, _ = spearmanr(norm1, algo_score)\n",
    "#print('Spearmans correlation: %.3f' % corr)\n",
    "spearman_ls.append(corrs) \n",
    "print (np.round(corrs,2))\n",
    "#df_score.lo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check results \n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col0,#T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col1,#T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col2,#T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col3,#T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col4,#T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col6,#T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col7,#T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col5{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >mc30</th>        <th class=\"col_heading level0 col1\" >ws353</th>        <th class=\"col_heading level0 col2\" >verb143</th>        <th class=\"col_heading level0 col3\" >rg65</th>        <th class=\"col_heading level0 col4\" >YP130</th>        <th class=\"col_heading level0 col5\" >simlex999</th>        <th class=\"col_heading level0 col6\" >rw</th>        <th class=\"col_heading level0 col7\" >wordsimSim</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122level0_row0\" class=\"row_heading level0 row0\" >SP : spearman</th>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col0\" class=\"data row0 col0\" >0.509738</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col1\" class=\"data row0 col1\" >0.283972</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col2\" class=\"data row0 col2\" >0.196846</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col3\" class=\"data row0 col3\" >0.657737</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col4\" class=\"data row0 col4\" >0.473691</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col5\" class=\"data row0 col5\" >0.366731</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col6\" class=\"data row0 col6\" >0.198774</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row0_col7\" class=\"data row0 col7\" >0.496549</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122level0_row1\" class=\"row_heading level0 row1\" >SP : Pearson</th>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col0\" class=\"data row1 col0\" >0.489521</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col1\" class=\"data row1 col1\" >0.254977</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col2\" class=\"data row1 col2\" >0.133855</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col3\" class=\"data row1 col3\" >0.655934</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col4\" class=\"data row1 col4\" >0.467584</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col5\" class=\"data row1 col5\" >0.379607</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col6\" class=\"data row1 col6\" >0.189695</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row1_col7\" class=\"data row1 col7\" >0.487518</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122level0_row2\" class=\"row_heading level0 row2\" >Leacock : spearman</th>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row2_col0\" class=\"data row2 col0\" >-0.383200</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row2_col1\" class=\"data row2 col1\" >-0.114225</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row2_col2\" class=\"data row2 col2\" >0.035563</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row2_col3\" class=\"data row2 col3\" >-0.266795</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row2_col4\" class=\"data row2 col4\" >-0.023329</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row2_col5\" class=\"data row2 col5\" >-0.262912</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row2_col6\" class=\"data row2 col6\" >-0.214483</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row2_col7\" class=\"data row2 col7\" >-0.131478</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122level0_row3\" class=\"row_heading level0 row3\" >Leacock : Pearson</th>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row3_col0\" class=\"data row3 col0\" >-0.300321</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row3_col1\" class=\"data row3 col1\" >-0.101877</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row3_col2\" class=\"data row3 col2\" >-0.006449</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row3_col3\" class=\"data row3 col3\" >-0.340009</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row3_col4\" class=\"data row3 col4\" >0.017026</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row3_col5\" class=\"data row3 col5\" >-0.263540</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row3_col6\" class=\"data row3 col6\" >-0.225336</td>\n",
       "                        <td id=\"T_32c6dd18_bcc1_11eb_8408_acde48001122row3_col7\" class=\"data row3 col7\" >-0.128977</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb83e7ffcd0>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result_dict).T\n",
    "df.columns = columns\n",
    "df.style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_4592a774_bcc1_11eb_8408_acde48001122row0_col2,#T_4592a774_bcc1_11eb_8408_acde48001122row0_col4,#T_4592a774_bcc1_11eb_8408_acde48001122row0_col6,#T_4592a774_bcc1_11eb_8408_acde48001122row1_col4,#T_4592a774_bcc1_11eb_8408_acde48001122row4_col7,#T_4592a774_bcc1_11eb_8408_acde48001122row5_col0,#T_4592a774_bcc1_11eb_8408_acde48001122row7_col1,#T_4592a774_bcc1_11eb_8408_acde48001122row7_col3,#T_4592a774_bcc1_11eb_8408_acde48001122row9_col0,#T_4592a774_bcc1_11eb_8408_acde48001122row9_col5{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_4592a774_bcc1_11eb_8408_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >mc30</th>        <th class=\"col_heading level0 col1\" >ws353</th>        <th class=\"col_heading level0 col2\" >verb143</th>        <th class=\"col_heading level0 col3\" >rg65</th>        <th class=\"col_heading level0 col4\" >YP130</th>        <th class=\"col_heading level0 col5\" >simlex999</th>        <th class=\"col_heading level0 col6\" >rw</th>        <th class=\"col_heading level0 col7\" >wordsimSim</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row0\" class=\"row_heading level0 row0\" >SP : spearman</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row0_col0\" class=\"data row0 col0\" >0.510000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row0_col1\" class=\"data row0 col1\" >0.280000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row0_col2\" class=\"data row0 col2\" >0.200000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row0_col3\" class=\"data row0 col3\" >0.660000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row0_col4\" class=\"data row0 col4\" >0.470000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row0_col5\" class=\"data row0 col5\" >0.370000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row0_col6\" class=\"data row0 col6\" >0.200000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row0_col7\" class=\"data row0 col7\" >0.500000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row1\" class=\"row_heading level0 row1\" >SP : Pearson</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row1_col0\" class=\"data row1 col0\" >0.490000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row1_col1\" class=\"data row1 col1\" >0.250000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row1_col2\" class=\"data row1 col2\" >0.130000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row1_col3\" class=\"data row1 col3\" >0.660000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row1_col4\" class=\"data row1 col4\" >0.470000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row1_col5\" class=\"data row1 col5\" >0.380000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row1_col6\" class=\"data row1 col6\" >0.190000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row1_col7\" class=\"data row1 col7\" >0.490000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row2\" class=\"row_heading level0 row2\" >Leacock : spearman</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row2_col0\" class=\"data row2 col0\" >-0.380000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row2_col1\" class=\"data row2 col1\" >-0.110000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row2_col2\" class=\"data row2 col2\" >0.040000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row2_col3\" class=\"data row2 col3\" >-0.270000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row2_col4\" class=\"data row2 col4\" >-0.020000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row2_col5\" class=\"data row2 col5\" >-0.260000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row2_col6\" class=\"data row2 col6\" >-0.210000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row2_col7\" class=\"data row2 col7\" >-0.130000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row3\" class=\"row_heading level0 row3\" >Leacock : Pearson</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row3_col0\" class=\"data row3 col0\" >-0.300000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row3_col1\" class=\"data row3 col1\" >-0.100000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row3_col2\" class=\"data row3 col2\" >-0.010000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row3_col3\" class=\"data row3 col3\" >-0.340000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row3_col4\" class=\"data row3 col4\" >0.020000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row3_col5\" class=\"data row3 col5\" >-0.260000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row3_col6\" class=\"data row3 col6\" >-0.230000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row3_col7\" class=\"data row3 col7\" >-0.130000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row4\" class=\"row_heading level0 row4\" >wup : spearman</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row4_col0\" class=\"data row4 col0\" >0.750000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row4_col1\" class=\"data row4 col1\" >0.350000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row4_col2\" class=\"data row4 col2\" >0.050000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row4_col3\" class=\"data row4 col3\" >0.540000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row4_col4\" class=\"data row4 col4\" >0.050000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row4_col5\" class=\"data row4 col5\" >0.550000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row4_col6\" class=\"data row4 col6\" >-0.030000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row4_col7\" class=\"data row4 col7\" >0.620000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row5\" class=\"row_heading level0 row5\" >wup : Pearson</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row5_col0\" class=\"data row5 col0\" >0.780000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row5_col1\" class=\"data row5 col1\" >0.310000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row5_col2\" class=\"data row5 col2\" >-0.010000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row5_col3\" class=\"data row5 col3\" >0.520000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row5_col4\" class=\"data row5 col4\" >0.080000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row5_col5\" class=\"data row5 col5\" >0.540000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row5_col6\" class=\"data row5 col6\" >-0.030000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row5_col7\" class=\"data row5 col7\" >0.580000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row6\" class=\"row_heading level0 row6\" >path : spearman</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row6_col0\" class=\"data row6 col0\" >0.720000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row6_col1\" class=\"data row6 col1\" >0.310000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row6_col2\" class=\"data row6 col2\" >0.060000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row6_col3\" class=\"data row6 col3\" >0.550000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row6_col4\" class=\"data row6 col4\" >0.050000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row6_col5\" class=\"data row6 col5\" >0.620000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row6_col6\" class=\"data row6 col6\" >-0.040000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row6_col7\" class=\"data row6 col7\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row7\" class=\"row_heading level0 row7\" >path : Pearson</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row7_col0\" class=\"data row7 col0\" >0.750000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row7_col1\" class=\"data row7 col1\" >0.380000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row7_col2\" class=\"data row7 col2\" >0.020000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row7_col3\" class=\"data row7 col3\" >0.680000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row7_col4\" class=\"data row7 col4\" >0.170000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row7_col5\" class=\"data row7 col5\" >0.580000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row7_col6\" class=\"data row7 col6\" >0.030000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row7_col7\" class=\"data row7 col7\" >0.590000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row8\" class=\"row_heading level0 row8\" >lch : spearman</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row8_col0\" class=\"data row8 col0\" >0.720000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row8_col1\" class=\"data row8 col1\" >0.310000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row8_col2\" class=\"data row8 col2\" >0.060000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row8_col3\" class=\"data row8 col3\" >0.550000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row8_col4\" class=\"data row8 col4\" >0.050000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row8_col5\" class=\"data row8 col5\" >0.620000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row8_col6\" class=\"data row8 col6\" >-0.040000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row8_col7\" class=\"data row8 col7\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_4592a774_bcc1_11eb_8408_acde48001122level0_row9\" class=\"row_heading level0 row9\" >lch : Pearson</th>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row9_col0\" class=\"data row9 col0\" >0.780000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row9_col1\" class=\"data row9 col1\" >0.350000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row9_col2\" class=\"data row9 col2\" >0.010000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row9_col3\" class=\"data row9 col3\" >0.560000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row9_col4\" class=\"data row9 col4\" >0.090000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row9_col5\" class=\"data row9 col5\" >0.630000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row9_col6\" class=\"data row9 col6\" >-0.020000</td>\n",
       "                        <td id=\"T_4592a774_bcc1_11eb_8408_acde48001122row9_col7\" class=\"data row9 col7\" >0.610000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fb83c4d6fd0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sematch = pd.read_csv('sematch_KRbased_result.csv')\n",
    "df_sematch = df_sematch.set_index('Unnamed: 0')\n",
    "df_final  = round( pd.concat([df, df_sematch]),2)\n",
    "df_final.style.highlight_max(color = 'lightgreen', axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col3,#T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col4,#T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col5,#T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col7,#T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col5,#T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col8,#T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col1,#T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col2,#T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col4,#T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col1,#T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col6{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Unnamed: 0</th>        <th class=\"col_heading level0 col1\" >mc30</th>        <th class=\"col_heading level0 col2\" >ws353</th>        <th class=\"col_heading level0 col3\" >verb143</th>        <th class=\"col_heading level0 col4\" >rg65</th>        <th class=\"col_heading level0 col5\" >YP130</th>        <th class=\"col_heading level0 col6\" >simlex999</th>        <th class=\"col_heading level0 col7\" >rw</th>        <th class=\"col_heading level0 col8\" >wordsimSim</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col0\" class=\"data row0 col0\" >SP : spearman</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col1\" class=\"data row0 col1\" >0.510000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col2\" class=\"data row0 col2\" >0.280000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col3\" class=\"data row0 col3\" >0.200000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col4\" class=\"data row0 col4\" >0.680000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col5\" class=\"data row0 col5\" >0.470000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col6\" class=\"data row0 col6\" >0.370000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col7\" class=\"data row0 col7\" >0.200000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row0_col8\" class=\"data row0 col8\" >0.500000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col0\" class=\"data row1 col0\" >SP : Pearson</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col1\" class=\"data row1 col1\" >0.490000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col2\" class=\"data row1 col2\" >0.250000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col3\" class=\"data row1 col3\" >0.130000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col4\" class=\"data row1 col4\" >0.660000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col5\" class=\"data row1 col5\" >0.470000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col6\" class=\"data row1 col6\" >0.380000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col7\" class=\"data row1 col7\" >0.190000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row1_col8\" class=\"data row1 col8\" >0.490000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col0\" class=\"data row2 col0\" >Leacock : spearman</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col1\" class=\"data row2 col1\" >-0.380000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col2\" class=\"data row2 col2\" >-0.110000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col3\" class=\"data row2 col3\" >0.040000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col4\" class=\"data row2 col4\" >-0.270000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col5\" class=\"data row2 col5\" >-0.020000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col6\" class=\"data row2 col6\" >-0.260000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col7\" class=\"data row2 col7\" >-0.210000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row2_col8\" class=\"data row2 col8\" >-0.130000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col0\" class=\"data row3 col0\" >Leacock : Pearson</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col1\" class=\"data row3 col1\" >-0.300000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col2\" class=\"data row3 col2\" >-0.100000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col3\" class=\"data row3 col3\" >-0.010000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col4\" class=\"data row3 col4\" >-0.340000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col5\" class=\"data row3 col5\" >0.020000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col6\" class=\"data row3 col6\" >-0.260000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col7\" class=\"data row3 col7\" >-0.230000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row3_col8\" class=\"data row3 col8\" >-0.130000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col0\" class=\"data row4 col0\" >wup : spearman</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col1\" class=\"data row4 col1\" >0.750000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col2\" class=\"data row4 col2\" >0.350000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col3\" class=\"data row4 col3\" >0.050000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col4\" class=\"data row4 col4\" >0.540000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col5\" class=\"data row4 col5\" >0.050000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col6\" class=\"data row4 col6\" >0.550000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col7\" class=\"data row4 col7\" >-0.030000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row4_col8\" class=\"data row4 col8\" >0.620000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col0\" class=\"data row5 col0\" >wup : Pearson</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col1\" class=\"data row5 col1\" >0.780000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col2\" class=\"data row5 col2\" >0.310000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col3\" class=\"data row5 col3\" >-0.010000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col4\" class=\"data row5 col4\" >0.520000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col5\" class=\"data row5 col5\" >0.080000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col6\" class=\"data row5 col6\" >0.540000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col7\" class=\"data row5 col7\" >-0.030000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row5_col8\" class=\"data row5 col8\" >0.580000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col0\" class=\"data row6 col0\" >path : spearman</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col1\" class=\"data row6 col1\" >0.720000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col2\" class=\"data row6 col2\" >0.310000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col3\" class=\"data row6 col3\" >0.060000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col4\" class=\"data row6 col4\" >0.550000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col5\" class=\"data row6 col5\" >0.050000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col6\" class=\"data row6 col6\" >0.620000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col7\" class=\"data row6 col7\" >-0.040000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row6_col8\" class=\"data row6 col8\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col0\" class=\"data row7 col0\" >path : Pearson</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col1\" class=\"data row7 col1\" >0.750000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col2\" class=\"data row7 col2\" >0.380000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col3\" class=\"data row7 col3\" >0.020000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col4\" class=\"data row7 col4\" >0.680000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col5\" class=\"data row7 col5\" >0.170000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col6\" class=\"data row7 col6\" >0.580000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col7\" class=\"data row7 col7\" >0.030000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row7_col8\" class=\"data row7 col8\" >0.590000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col0\" class=\"data row8 col0\" >lch : spearman</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col1\" class=\"data row8 col1\" >0.720000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col2\" class=\"data row8 col2\" >0.310000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col3\" class=\"data row8 col3\" >0.060000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col4\" class=\"data row8 col4\" >0.550000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col5\" class=\"data row8 col5\" >0.050000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col6\" class=\"data row8 col6\" >0.620000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col7\" class=\"data row8 col7\" >-0.040000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row8_col8\" class=\"data row8 col8\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col0\" class=\"data row9 col0\" >lch : Pearson</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col1\" class=\"data row9 col1\" >0.780000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col2\" class=\"data row9 col2\" >0.350000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col3\" class=\"data row9 col3\" >0.010000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col4\" class=\"data row9 col4\" >0.560000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col5\" class=\"data row9 col5\" >0.090000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col6\" class=\"data row9 col6\" >0.630000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col7\" class=\"data row9 col7\" >-0.020000</td>\n",
       "                        <td id=\"T_9530bdb2_bd24_11eb_abd8_acde48001122row9_col8\" class=\"data row9 col8\" >0.610000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdf784ea690>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sem_Evaluation_KR.csv').style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "#T_9df97630_bd26_11eb_abd8_acde48001122row0_col3,#T_9df97630_bd26_11eb_abd8_acde48001122row0_col4,#T_9df97630_bd26_11eb_abd8_acde48001122row0_col5,#T_9df97630_bd26_11eb_abd8_acde48001122row0_col7,#T_9df97630_bd26_11eb_abd8_acde48001122row1_col5,#T_9df97630_bd26_11eb_abd8_acde48001122row4_col8,#T_9df97630_bd26_11eb_abd8_acde48001122row5_col1,#T_9df97630_bd26_11eb_abd8_acde48001122row7_col2,#T_9df97630_bd26_11eb_abd8_acde48001122row7_col4,#T_9df97630_bd26_11eb_abd8_acde48001122row9_col1,#T_9df97630_bd26_11eb_abd8_acde48001122row9_col6{\n",
       "            background-color:  lightgreen;\n",
       "        }</style><table id=\"T_9df97630_bd26_11eb_abd8_acde48001122\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Unnamed: 0</th>        <th class=\"col_heading level0 col1\" >mc30</th>        <th class=\"col_heading level0 col2\" >ws353</th>        <th class=\"col_heading level0 col3\" >verb143</th>        <th class=\"col_heading level0 col4\" >rg65</th>        <th class=\"col_heading level0 col5\" >YP130</th>        <th class=\"col_heading level0 col6\" >simlex999</th>        <th class=\"col_heading level0 col7\" >rw</th>        <th class=\"col_heading level0 col8\" >wordsimSim</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col0\" class=\"data row0 col0\" >SP : spearman</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col1\" class=\"data row0 col1\" >0.510000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col2\" class=\"data row0 col2\" >0.280000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col3\" class=\"data row0 col3\" >0.200000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col4\" class=\"data row0 col4\" >0.680000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col5\" class=\"data row0 col5\" >0.470000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col6\" class=\"data row0 col6\" >0.370000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col7\" class=\"data row0 col7\" >0.200000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row0_col8\" class=\"data row0 col8\" >0.500000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col0\" class=\"data row1 col0\" >SP : Pearson</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col1\" class=\"data row1 col1\" >0.490000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col2\" class=\"data row1 col2\" >0.250000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col3\" class=\"data row1 col3\" >0.130000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col4\" class=\"data row1 col4\" >0.660000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col5\" class=\"data row1 col5\" >0.470000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col6\" class=\"data row1 col6\" >0.380000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col7\" class=\"data row1 col7\" >0.190000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row1_col8\" class=\"data row1 col8\" >0.490000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col0\" class=\"data row2 col0\" >Leacock : spearman</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col1\" class=\"data row2 col1\" >-0.380000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col2\" class=\"data row2 col2\" >-0.110000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col3\" class=\"data row2 col3\" >0.040000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col4\" class=\"data row2 col4\" >-0.270000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col5\" class=\"data row2 col5\" >-0.020000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col6\" class=\"data row2 col6\" >-0.260000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col7\" class=\"data row2 col7\" >-0.210000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row2_col8\" class=\"data row2 col8\" >-0.130000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col0\" class=\"data row3 col0\" >Leacock : Pearson</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col1\" class=\"data row3 col1\" >-0.300000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col2\" class=\"data row3 col2\" >-0.100000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col3\" class=\"data row3 col3\" >-0.010000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col4\" class=\"data row3 col4\" >-0.340000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col5\" class=\"data row3 col5\" >0.020000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col6\" class=\"data row3 col6\" >-0.260000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col7\" class=\"data row3 col7\" >-0.230000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row3_col8\" class=\"data row3 col8\" >-0.130000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col0\" class=\"data row4 col0\" >wup : spearman</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col1\" class=\"data row4 col1\" >0.750000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col2\" class=\"data row4 col2\" >0.350000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col3\" class=\"data row4 col3\" >0.050000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col4\" class=\"data row4 col4\" >0.540000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col5\" class=\"data row4 col5\" >0.050000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col6\" class=\"data row4 col6\" >0.550000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col7\" class=\"data row4 col7\" >-0.030000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row4_col8\" class=\"data row4 col8\" >0.620000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col0\" class=\"data row5 col0\" >wup : Pearson</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col1\" class=\"data row5 col1\" >0.780000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col2\" class=\"data row5 col2\" >0.310000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col3\" class=\"data row5 col3\" >-0.010000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col4\" class=\"data row5 col4\" >0.520000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col5\" class=\"data row5 col5\" >0.080000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col6\" class=\"data row5 col6\" >0.540000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col7\" class=\"data row5 col7\" >-0.030000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row5_col8\" class=\"data row5 col8\" >0.580000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col0\" class=\"data row6 col0\" >path : spearman</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col1\" class=\"data row6 col1\" >0.720000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col2\" class=\"data row6 col2\" >0.310000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col3\" class=\"data row6 col3\" >0.060000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col4\" class=\"data row6 col4\" >0.550000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col5\" class=\"data row6 col5\" >0.050000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col6\" class=\"data row6 col6\" >0.620000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col7\" class=\"data row6 col7\" >-0.040000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row6_col8\" class=\"data row6 col8\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col0\" class=\"data row7 col0\" >path : Pearson</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col1\" class=\"data row7 col1\" >0.750000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col2\" class=\"data row7 col2\" >0.380000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col3\" class=\"data row7 col3\" >0.020000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col4\" class=\"data row7 col4\" >0.680000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col5\" class=\"data row7 col5\" >0.170000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col6\" class=\"data row7 col6\" >0.580000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col7\" class=\"data row7 col7\" >0.030000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row7_col8\" class=\"data row7 col8\" >0.590000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col0\" class=\"data row8 col0\" >lch : spearman</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col1\" class=\"data row8 col1\" >0.720000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col2\" class=\"data row8 col2\" >0.310000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col3\" class=\"data row8 col3\" >0.060000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col4\" class=\"data row8 col4\" >0.550000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col5\" class=\"data row8 col5\" >0.050000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col6\" class=\"data row8 col6\" >0.620000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col7\" class=\"data row8 col7\" >-0.040000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row8_col8\" class=\"data row8 col8\" >0.600000</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_9df97630_bd26_11eb_abd8_acde48001122level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col0\" class=\"data row9 col0\" >lch : Pearson</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col1\" class=\"data row9 col1\" >0.780000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col2\" class=\"data row9 col2\" >0.350000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col3\" class=\"data row9 col3\" >0.010000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col4\" class=\"data row9 col4\" >0.560000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col5\" class=\"data row9 col5\" >0.090000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col6\" class=\"data row9 col6\" >0.630000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col7\" class=\"data row9 col7\" >-0.020000</td>\n",
       "                        <td id=\"T_9df97630_bd26_11eb_abd8_acde48001122row9_col8\" class=\"data row9 col8\" >0.610000</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fdf7e167390>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('sem_Evaluation_IC.csv').style.highlight_max(color = 'lightgreen', axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
