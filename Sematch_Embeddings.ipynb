{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Measures : Lin, Resnik , WUP, LI, Path, LCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets : Verb , Noun , NVA (noun + verb + adjective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sematch.semantic.similarity import WordNetSimilarity\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from scipy import stats\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "from scipy.stats import spearmanr\n",
    "import itertools\n",
    "from scipy import spatial\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.spatial.distance import cdist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/NOUN_rg-65.csv\n",
      "datasets/mturk-771.csv\n",
      "datasets/VERB_verb-143.csv\n",
      "datasets/VERB_yp-130.csv\n",
      "datasets/rw.csv\n",
      "datasets/wordsim353-rel.csv\n",
      "datasets/NOUN_mc-30.csv\n",
      "datasets/men.csv\n",
      "datasets/mturk-287.csv\n",
      "datasets/wordsim353-sim.csv\n",
      "datasets/NOUN_rg-65.csv\n",
      "datasets/mturk-771.csv\n",
      "datasets/VERB_verb-143.csv\n",
      "datasets/VERB_yp-130.csv\n",
      "datasets/rw.csv\n",
      "datasets/wordsim353-rel.csv\n",
      "datasets/NOUN_mc-30.csv\n",
      "datasets/men.csv\n",
      "datasets/mturk-287.csv\n",
      "datasets/wordsim353-sim.csv\n",
      "datasets/NOUN_rg-65.csv\n",
      "datasets/mturk-771.csv\n",
      "datasets/VERB_verb-143.csv\n",
      "datasets/VERB_yp-130.csv\n",
      "datasets/rw.csv\n",
      "datasets/wordsim353-rel.csv\n",
      "datasets/NOUN_mc-30.csv\n",
      "datasets/men.csv\n",
      "datasets/mturk-287.csv\n",
      "datasets/wordsim353-sim.csv\n",
      "datasets/NOUN_rg-65.csv\n",
      "datasets/mturk-771.csv\n",
      "datasets/VERB_verb-143.csv\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ab3febee61ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mancestors_distance\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_pairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0mancestors_distance\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malgoname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVERB\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 0.449327301063\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/utility.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m          \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m          \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m          \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/semantic/similarity.py\u001b[0m in \u001b[0;36mword_similarity\u001b[0;34m(self, w1, w2, name, pos)\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0msim_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_synset_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mmemoized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/semantic/similarity.py\u001b[0m in \u001b[0;36mmax_synset_similarity\u001b[0;34m(self, syns1, syns2, sim_metric)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0msemantic\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msim_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyns1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyns2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mmemoized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/semantic/similarity.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmaximum\u001b[0m \u001b[0msemantic\u001b[0m \u001b[0msimilarity\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m         \"\"\"\n\u001b[0;32m--> 311\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msim_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyns1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msyns2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mmemoized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/semantic/similarity.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0ms2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2synset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         \u001b[0msim_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    318\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_synset_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/utility.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     77\u001b[0m          \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m          \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m          \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/semantic/similarity.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, c1, c2, name)\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \"\"\"\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmax_synset_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyns1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyns2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim_metric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/semantic/similarity.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(syn1, syn2)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyn1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyn2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/semantic/similarity.py\u001b[0m in \u001b[0;36mli\u001b[0;34m(self, c1, c2, alpha, beta)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mli\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshortest_path_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m         \u001b[0mlcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleast_common_subsumer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0mdepth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sematch/semantic/similarity.py\u001b[0m in \u001b[0;36mleast_common_subsumer\u001b[0;34m(self, c1, c2)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mleast_common_subsumer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 369\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mc1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowest_common_hypernyms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    371\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msynset_ic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "wns = WordNetSimilarity()\n",
    "goldData= glob.glob(\"datasets/*.csv\")\n",
    "\n",
    "algos = [  'path', 'lch', 'wup', 'li'] #'res''lin', ]#,'jcn' , \n",
    "column_names = ['word1', 'word2', 'sim']\n",
    "for algoname in algos:\n",
    "    \n",
    "    for file in goldData:\n",
    "        \n",
    "        print (file)\n",
    "        ls = []\n",
    "        word_list = []\n",
    "        df = pd.read_csv(file)#,  names = column_names) #sep=';',\n",
    "        # copy word pairs to save result\n",
    "        df_r = df[['word1', 'word2']]\n",
    "        # make word pairs\n",
    "        #word_pairs = list(zip(df['word1'], df['word2']))\n",
    "        \n",
    "        wd1 =  df['word1'].values.tolist()\n",
    "        wd2 =  df['word2'].values.tolist()\n",
    "            \n",
    "        #word_pairs =list(zip(wd1, wd2))\n",
    "        word_pairs = list(itertools.product(wd1+wd2, repeat=2))\n",
    "           \n",
    "        \n",
    "        if file.split('/')[1].split('_')[0].lower() =='noun':\n",
    "            ancestors_distance = {}\n",
    "            for i in word_pairs:\n",
    "                ancestors_distance[i] = wns.word_similarity(i[0], i[1], algoname, wn.NOUN) # 0.449327301063\n",
    "            \n",
    "                 \n",
    "                \n",
    "            # normalize in 0 -1\n",
    "            values = ancestors_distance.values()\n",
    "            minimum = min(values)\n",
    "            maximum = max(values)\n",
    "            d = maximum - minimum \n",
    "            for k in ancestors_distance:\n",
    "                  ancestors_distance[k] = (ancestors_distance[k]- minimum)/d\n",
    "            \n",
    "            \n",
    "            # create adjancey matrix\n",
    "            chunked_data = [[k[0],k[1], v] for k, v in ancestors_distance.items()]\n",
    "            df_nodes = pd.DataFrame(chunked_data)\n",
    "            df_nodes = df_nodes.rename(columns= {0:'node1', 1:'node2', 2:'weight'})\n",
    "\n",
    "             # create adjancey matrix\n",
    "            vals = np.unique(df_nodes[['node1', 'node2']])\n",
    "            df_nodes = df_nodes.pivot(index='node1', columns='node2', values='weight'\n",
    "                              ).reindex(columns=vals, index=vals, fill_value=0)\n",
    "\n",
    "            df_adjacency = df_nodes#.apply( lambda x:   lambda_factor** x)\n",
    "            target_filename = './Embeddings/'+algoname+'>'+file.split('/')[1]\n",
    "            df_adjacency.to_csv(target_filename)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            #df_r.to_csv('./sim_scores/'+algoname+'>'+file.split('/')[1])\n",
    "        elif file.split('/')[1].split('_')[0].lower() =='verb':\n",
    "            ancestors_distance = {}\n",
    "            for i in word_pairs:\n",
    "                ancestors_distance[i] = wns.word_similarity(i[0], i[1], algoname, wn.VERB) # 0.449327301063\n",
    "            \n",
    "                 \n",
    "             # create adjancey matrix\n",
    "            chunked_data = [[k[0],k[1], v] for k, v in ancestors_distance.items()]\n",
    "            df_nodes = pd.DataFrame(chunked_data)\n",
    "            df_nodes = df_nodes.rename(columns= {0:'node1', 1:'node2', 2:'weight'})\n",
    "\n",
    "             # create adjancey matrix\n",
    "            vals = np.unique(df_nodes[['node1', 'node2']])\n",
    "            df_nodes = df_nodes.pivot(index='node1', columns='node2', values='weight'\n",
    "                              ).reindex(columns=vals, index=vals, fill_value=0)\n",
    "\n",
    "            df_adjacency = df_nodes#.apply( lambda x:   lambda_factor** x)\n",
    "            target_filename = './Embeddings/'+algoname+'>'+file.split('/')[1]\n",
    "            df_adjacency.to_csv(target_filename)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #df_r.to_csv('./sim_scores/'+algoname+'>'+file.split('/')[1])\n",
    "        else:\n",
    "            #for i in word_pairs:\n",
    "            #    ls.append(wns.word_similarity(i[0], i[1], algoname, 'None')) # 0.449327301063\n",
    "            #df_r['sim'] = ls\n",
    "            #df_r.to_csv('./sim_scores/'+algoname+file.split('/')[1])\n",
    "            pass\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23680261, 0.        , 0.26216094, 0.63931758, 0.23483385,\n",
       "       0.21799319, 0.26216094, 0.12120179, 0.12814045, 0.20980968,\n",
       "       0.24966786, 0.20709914, 0.22274329, 0.76222944, 0.13154627,\n",
       "       0.42294662, 0.21822166, 1.        , 0.63462091, 0.12120179,\n",
       "       0.        , 0.24677796, 0.29046255, 1.        , 0.        ,\n",
       "       0.22207477, 0.20339563, 0.19407074, 0.        , 0.21881126,\n",
       "       0.24677796, 0.        , 0.19982226, 0.21129148, 0.18358105,\n",
       "       0.53153296, 0.18061386, 0.22811218, 0.30844781, 0.22058251,\n",
       "       0.        , 0.24169313, 0.84770158, 0.27894013, 0.22323347,\n",
       "       0.        , 0.21793242, 0.13154627])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin\n",
      "65\n",
      "NOUN_rg-65.csv 0.73503723326482\n",
      "path\n",
      "126\n",
      "VERB_verb-143.csv 0.6167901058312732\n",
      "res\n",
      "130\n",
      "VERB_yp-130.csv 0.4468744113170061\n",
      "res\n",
      "65\n",
      "NOUN_rg-65.csv 0.7530372613910823\n",
      "wup\n",
      "30\n",
      "NOUN_mc-30.csv 0.5376582048688566\n",
      "lch\n",
      "126\n",
      "VERB_verb-143.csv 0.4525331843643531\n",
      "res\n",
      "126\n",
      "VERB_verb-143.csv 0.4452143601119284\n",
      "path\n",
      "30\n",
      "NOUN_mc-30.csv 0.7978158350152097\n",
      "lch\n",
      "30\n",
      "NOUN_mc-30.csv 0.6018246877145372\n",
      "lin\n",
      "126\n",
      "VERB_verb-143.csv 0.43416037649934114\n",
      "res\n",
      "30\n",
      "NOUN_mc-30.csv 0.8313563387496262\n",
      "wup\n",
      "130\n",
      "VERB_yp-130.csv 0.5160852566369054\n",
      "wup\n",
      "126\n",
      "VERB_verb-143.csv 0.5151373248054765\n",
      "lin\n",
      "30\n",
      "NOUN_mc-30.csv 0.8128397319494671\n",
      "lch\n",
      "65\n",
      "NOUN_rg-65.csv 0.6498699752419506\n",
      "path\n",
      "65\n",
      "NOUN_rg-65.csv 0.8455005313749898\n",
      "wup\n",
      "65\n",
      "NOUN_rg-65.csv 0.5018340300563138\n",
      "path\n",
      "130\n",
      "VERB_yp-130.csv 0.6173836505662484\n",
      "li\n",
      "65\n",
      "NOUN_rg-65.csv 0.6956834545436723\n",
      "lin\n",
      "130\n",
      "VERB_yp-130.csv 0.4389389665489508\n",
      "lch\n",
      "130\n",
      "VERB_yp-130.csv 0.45645266491243575\n"
     ]
    }
   ],
   "source": [
    "goldDatapath= './datasets/'\n",
    "sim_data = glob.glob(\"./Embeddings/*.csv\")\n",
    "for file in sim_data:\n",
    "    emb = pd.read_csv(file)\n",
    "    print(file.split('/')[2].split('>')[0])\n",
    "    fname = file.split('/')[2].split('>')[1]\n",
    "    dftest = pd.read_csv('./datasets/'+fname)\n",
    "    \n",
    "    wordpairs = list (zip(dftest['word1'].values, dftest['word2'].values))\n",
    "    print (len(wordpairs))\n",
    "    ls_sim = []\n",
    "    ls=[]\n",
    "    for i in wordpairs:\n",
    "        a= emb.loc[emb['node1']== i[0]].values[0][1:].astype(float)\n",
    "        b = emb.loc[emb['node1']== i[1]].values[0][1:].astype(float)\n",
    "        ma = np.linalg.norm(a)\n",
    "        mb = np.linalg.norm(b)\n",
    "\n",
    "        # Cosine Similarity\n",
    "        sim = (np.matmul(a,b))/(ma*mb)\n",
    "        ls.append(sim)\n",
    "    # calculate similarity    \n",
    "    score_human = dftest['similarity'].values\n",
    "    norm1 = [(float(i)-min(score_human))/(max(score_human )-min(score_human )) for i in score_human ] # normalize score in 0-1\n",
    "    corrp, _ = pearsonr(norm1, ls)\n",
    "    print (fname, corrp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./sim_scores/lin>NOUN_rg-65.csv\n",
      "0.8582467403072271\n",
      "./sim_scores/path>VERB_verb-143.csv\n",
      "0.7419046187450109\n",
      "./sim_scores/res>VERB_yp-130.csv\n",
      "0.6876081952035764\n",
      "./sim_scores/res>NOUN_rg-65.csv\n",
      "0.8363542537890224\n",
      "./sim_scores/lch>VERB_verb-143.csv\n",
      "0.754279345215062\n",
      "./sim_scores/res>VERB_verb-143.csv\n",
      "0.6889088065146809\n",
      "./sim_scores/path>NOUN_mc-30.csv\n",
      "0.7546804798013202\n",
      "./sim_scores/lch>NOUN_mc-30.csv\n",
      "0.7792227870080043\n",
      "./sim_scores/lin>VERB_verb-143.csv\n",
      "0.712965295515785\n",
      "./sim_scores/res>NOUN_mc-30.csv\n",
      "0.8133107841698882\n",
      "./sim_scores/lin>NOUN_mc-30.csv\n",
      "0.8353845147818655\n",
      "./sim_scores/lch>NOUN_rg-65.csv\n",
      "0.838645483549906\n",
      "./sim_scores/path>NOUN_rg-65.csv\n",
      "0.7842489016391186\n",
      "./sim_scores/path>VERB_yp-130.csv\n",
      "0.738158641552499\n",
      "./sim_scores/lin>VERB_yp-130.csv\n",
      "0.7111069404098043\n",
      "./sim_scores/lch>VERB_yp-130.csv\n",
      "0.7516279354841879\n"
     ]
    }
   ],
   "source": [
    "pearson_ls = []\n",
    "spearman_ls = [] \n",
    "result_dict = {}\n",
    "goldDatapath= './datasets/'\n",
    "sim_data = glob.glob(\"./Embeddings/*.csv\")\n",
    "\n",
    "for file in sim_data:\n",
    "    print (file)\n",
    "    algoname = file.split('/')[2].split('sss')[0]\n",
    "    \n",
    "    filename = file.split('/')[-1].split('>')[1]\n",
    "    # read human similarity score\n",
    "    df = pd.read_csv(goldDatapath+filename)\n",
    "    score_human = df['similarity'].values\n",
    "    norm1 = [(float(i)-min(score_human))/(max(score_human )-min(score_human )) for i in score_human ] # normalize score in 0-1\n",
    "    \n",
    "    for algoname in algos:\n",
    "        # read similarity file\n",
    "        df_r = pd.read_csv(file)\n",
    "        \n",
    "        algo_score = df_r['sim'].values\n",
    "        # normalize score\n",
    "        if (df_r['sim'] > 1).any():\n",
    "            algo_score= [(float(i)-min(algo_score))/(max(algo_score )-min(algo_score )) for i in algo_score ] # normalize score in 0-1\n",
    "    \n",
    "        # calculate Pearson's correlation\n",
    "        \n",
    "        corrp, _ = pearsonr(norm1, algo_score)\n",
    "        pearson_ls.append(corrp) \n",
    "        print (corrp)\n",
    "        corrs, _ = spearmanr(norm1, algo_score)\n",
    "        #print('Spearmans correlation: %.3f' % corr)\n",
    "        spearman_ls.append(corrs) \n",
    "#df_score.loc[len(df_score.index)+1] =pearson_ls\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SimLex222</th>\n",
       "      <th>Agirre201</th>\n",
       "      <th>Gerz</th>\n",
       "      <th>Millers</th>\n",
       "      <th>Rel122</th>\n",
       "      <th>wordsim353</th>\n",
       "      <th>yang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.437488</td>\n",
       "      <td>0.638203</td>\n",
       "      <td>0.46312</td>\n",
       "      <td>0.802281</td>\n",
       "      <td>0.18064</td>\n",
       "      <td>0.347393</td>\n",
       "      <td>0.754279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SimLex222  Agirre201     Gerz   Millers   Rel122  wordsim353      yang\n",
       "1   0.437488   0.638203  0.46312  0.802281  0.18064    0.347393  0.754279"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index= index_ls\n",
    "print('Pearsons correlation: ' , pearson_ls)\n",
    "df.loc[len(df.index)+1] =pearson_ls\n",
    "df.loc[len(df.index)+1] =spearman_ls\n",
    "        #result_dict[file.split('/')[2]+' : spearman'] = corrs\n",
    "        #result_dict[file.split('/')[2]+' : Pearson'] = corrp\n",
    "        #denom =np.add (spearman_ls , pearson_ls)\n",
    "        #ls = np.multiply(spearman_ls ,pearson_ls )\n",
    "        #ls = [x * 2 for x in ls]\n",
    "        #ls = ls/denom\n",
    "        #result_dict[algoname+' : harmonic mean'] =  ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEN</th>\n",
       "      <th>SimLex222</th>\n",
       "      <th>Agirre201</th>\n",
       "      <th>Gerz</th>\n",
       "      <th>Millers</th>\n",
       "      <th>Rel122</th>\n",
       "      <th>wordsim353</th>\n",
       "      <th>yang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.314527</td>\n",
       "      <td>0.303406</td>\n",
       "      <td>0.638203</td>\n",
       "      <td>0.45308</td>\n",
       "      <td>0.802281</td>\n",
       "      <td>0.208118</td>\n",
       "      <td>0.33933</td>\n",
       "      <td>0.644862</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MEN  SimLex222  Agirre201     Gerz   Millers    Rel122  wordsim353  \\\n",
       "1  0.314527   0.303406   0.638203  0.45308  0.802281  0.208118     0.33933   \n",
       "\n",
       "       yang  \n",
       "1  0.644862  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.loc[len(df.index)+1] =pearson_ls\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lchMEN': 0.3145271705169845,\n",
       " 'lchSimLex222': 0.3034056209777609,\n",
       " 'lchAgirre201': 0.6382032580302167,\n",
       " 'lchGerz': 0.4530796918550536,\n",
       " 'lchMiller': 0.8022809513667366,\n",
       " 'lchRel122': 0.20811782395827375,\n",
       " 'lchWordSim353Full': 0.33932983545941775,\n",
       " 'lchYang': 0.6448617824571327}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_d = {}\n",
    "for k,v in result_dict.items():\n",
    "    r_d[k.split('sss')[0]+k.split('_')[1]] =v\n",
    "    #print (k.split('sss')[0],k.split('_')[1],v)\n",
    "r_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-04e6e6a7814b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'MEN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SimLex222'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Agirre201'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Gerz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Millers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Rel122'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wordsim353'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'yang'\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "columns =['MEN', 'SimLex222','Agirre201', 'Gerz', 'Millers', 'Rel122', 'wordsim353', 'yang' ]\n",
    "df =pd.DataFrame(r_d)\n",
    "df.columns = columns\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-65c47f05c64e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhighlight_max\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'lightgreen'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#df.to_csv('sematch_KRbased_NEWdatasets.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(result_dict).T\n",
    "df.columns = columns\n",
    "df.style.highlight_max(color = 'lightgreen', axis = 0)\n",
    "#df.to_csv('sematch_KRbased_NEWdatasets.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "wns = WordNetSimilarity()\n",
    "goldData_path = glob.glob(\"datasets_wordpairSim/*.csv\")\n",
    "#sample_data = glob.glob(\"sim_scores/SPAllSynsets/*.csv\")\n",
    "result_dict = {}\n",
    "\n",
    "columns = [col.split('/')[-1].split('.')[0] for col in goldData_path ]\n",
    "algos = ['lin', 'res','jcn']\n",
    "for algoname in algos:\n",
    "    pearson_ls = []\n",
    "    spearman_ls = []\n",
    "    for file in goldData_path:\n",
    "        ls = []\n",
    "        \n",
    "        column_names = ['word1', 'word2', 'sim']\n",
    "        word_list = []\n",
    "        df = pd.read_csv(file, sep=';', names = column_names)\n",
    "        \n",
    "        word_list.append(df['word1'])\n",
    "        word_list.append(df['word2'])\n",
    "        df_r = df\n",
    "        # make word pairs\n",
    "        word_pairs = list(zip(df['word1'], df['word2']))\n",
    "        for i in word_pairs:\n",
    "            ls.append(wns.word_similarity(i[0], i[1], algoname)) # 0.449327301063\n",
    "        df_r['sim'] = ls\n",
    "\n",
    "        df = pd.read_csv('./datasets_wordpairSim/'+file.split('/')[-1], sep=';', names = column_names)\n",
    "        score_human = df['sim'].values\n",
    "        norm1 = [(float(i)-min(score_human))/(max(score_human )-min(score_human )) for i in score_human ] # normalize score in 0-1\n",
    "        # calculate Pearson's correlation\n",
    "        corr, _ = pearsonr(norm1, ls)\n",
    "        pearson_ls.append(corr) \n",
    "        #print('Pearsons correlation: %.3f' % corr)\n",
    "        corr, _ = spearmanr(norm1, ls)\n",
    "        #print('Spearmans correlation: %.3f' % corr)\n",
    "        \n",
    "        spearman_ls.append(corr) \n",
    "        \n",
    "    result_dict[algoname+' : spearman'] = spearman_ls\n",
    "    result_dict[algoname+' : Pearson'] = pearson_ls\n",
    "    denom =np.add (spearman_ls , pearson_ls)\n",
    "    ls = np.multiply(spearman_ls ,pearson_ls )\n",
    "    ls = [x * 2 for x in ls]\n",
    "    ls = ls/denom\n",
    "    #result_dict[algoname+' : harmonic mean'] =  ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mc30</th>\n",
       "      <th>ws353</th>\n",
       "      <th>verb143</th>\n",
       "      <th>rg65</th>\n",
       "      <th>YP130</th>\n",
       "      <th>simlex999</th>\n",
       "      <th>rw</th>\n",
       "      <th>wordsimSim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lin : spearman</th>\n",
       "      <td>0.753677</td>\n",
       "      <td>0.309697</td>\n",
       "      <td>0.076222</td>\n",
       "      <td>0.574084</td>\n",
       "      <td>0.042394</td>\n",
       "      <td>0.592386</td>\n",
       "      <td>-0.035830</td>\n",
       "      <td>0.594564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lin : Pearson</th>\n",
       "      <td>0.835385</td>\n",
       "      <td>0.339889</td>\n",
       "      <td>0.013542</td>\n",
       "      <td>0.708439</td>\n",
       "      <td>0.159429</td>\n",
       "      <td>0.593751</td>\n",
       "      <td>0.029164</td>\n",
       "      <td>0.625695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res : spearman</th>\n",
       "      <td>0.732547</td>\n",
       "      <td>0.345752</td>\n",
       "      <td>0.076296</td>\n",
       "      <td>0.578005</td>\n",
       "      <td>0.043093</td>\n",
       "      <td>0.540040</td>\n",
       "      <td>-0.014712</td>\n",
       "      <td>0.623041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>res : Pearson</th>\n",
       "      <td>0.813311</td>\n",
       "      <td>0.373985</td>\n",
       "      <td>0.011875</td>\n",
       "      <td>0.702994</td>\n",
       "      <td>0.172498</td>\n",
       "      <td>0.541418</td>\n",
       "      <td>0.041423</td>\n",
       "      <td>0.660758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jcn : spearman</th>\n",
       "      <td>0.826223</td>\n",
       "      <td>0.284152</td>\n",
       "      <td>0.051511</td>\n",
       "      <td>0.529740</td>\n",
       "      <td>0.056913</td>\n",
       "      <td>0.593946</td>\n",
       "      <td>-0.046715</td>\n",
       "      <td>0.570249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jcn : Pearson</th>\n",
       "      <td>0.670445</td>\n",
       "      <td>0.340493</td>\n",
       "      <td>0.052359</td>\n",
       "      <td>0.656547</td>\n",
       "      <td>0.192533</td>\n",
       "      <td>0.547715</td>\n",
       "      <td>0.086883</td>\n",
       "      <td>0.515157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    mc30     ws353   verb143      rg65     YP130  simlex999  \\\n",
       "lin : spearman  0.753677  0.309697  0.076222  0.574084  0.042394   0.592386   \n",
       "lin : Pearson   0.835385  0.339889  0.013542  0.708439  0.159429   0.593751   \n",
       "res : spearman  0.732547  0.345752  0.076296  0.578005  0.043093   0.540040   \n",
       "res : Pearson   0.813311  0.373985  0.011875  0.702994  0.172498   0.541418   \n",
       "jcn : spearman  0.826223  0.284152  0.051511  0.529740  0.056913   0.593946   \n",
       "jcn : Pearson   0.670445  0.340493  0.052359  0.656547  0.192533   0.547715   \n",
       "\n",
       "                      rw  wordsimSim  \n",
       "lin : spearman -0.035830    0.594564  \n",
       "lin : Pearson   0.029164    0.625695  \n",
       "res : spearman -0.014712    0.623041  \n",
       "res : Pearson   0.041423    0.660758  \n",
       "jcn : spearman -0.046715    0.570249  \n",
       "jcn : Pearson   0.086883    0.515157  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(result_dict).T\n",
    "df.columns = columns\n",
    "df.style.highlight_max(color = 'lightgreen', axis = 0)\n",
    "df.to_csv('sematch_ICbased_result.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
